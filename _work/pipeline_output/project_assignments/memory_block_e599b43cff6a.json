{
  "id_hash": "e599b43cff6a",
  "summary": "#!/usr/bin/env python3\n\"\"\"\nMUSE Pantheon Universal Ingest Pipeline Orchestrator\nComplete pipeline: Ingest → Cluster → Assign Projects → Report\n\"\"\"\nimport sys\nimport pathlib\nimport argparse\nimport subprocess\nimport json\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import List, Dict, Any\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n\nclass PipelineOrchestrator:\n    \"\"\"Orchestrates the complete MUSE Pantheon ingest pipeline\"\"\"\n\n    def __init__(self, workspace_root: str):\n        self.workspace_root = pathlib.Path(workspace_root)\n        self.tools_dir = self.workspace_root / \"warden\" / \"tools\"\n        self.output_base = self.workspace_root / \"_work\" / \"pipeline_output\"\n        self.output_base.mkdir(parents=True, exist_ok=True)\n\n    def run_ingestion(self, roots: List[str], file_types: List[str] = None) -> bool:\n        \"\"\"Run the universal ingestion phase\"\"\"\n        logger.info(\"🚀 PHASE 1: Universal File Ingestion\")\n        logger.info(\"-\" * 40)\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"universal_ingest.py\"),\n            \"--roots\"\n        ] + roots + [\n            \"--output\", str(self.output_base / \"memory_blocks\")\n        ]\n\n        if file_types:\n            cmd.extend([\"--types\"] + file_types)\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"✅ Ingestion completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"❌ Ingestion failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"❌ Ingestion error: {e}\")\n            return False\n\n    def run_clustering(self) -> bool:\n        \"\"\"Run the clustering and embedding phase\"\"\"\n        logger.info(\"\\n🧠 PHASE 2: Clustering & Embeddings\")\n        logger.info(\"-\" * 40)\n\n        blocks_dir = self.output_base / \"memory_blocks\"\n        if not blocks_dir.exists() or not any(blocks_dir.glob(\"*.json\")):\n            logger.error(\"❌ Memory blocks directory not found or empty. Run ingestion first.\")\n            return False\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"cluster_embeddings.py\"),\n            \"--blocks-dir\", str(blocks_dir),\n            \"--output-dir\", str(self.output_base / \"clustering_results\")\n        ]\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"✅ Clustering completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"❌ Clustering failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"❌ Clustering error: {e}\")\n            return False\n\n    def run_project_assignment(self) -> bool:\n        \"\"\"Run the project assignment phase\"\"\"\n        logger.info(\"\\n🎯 PHASE 3: Project Assignment\")\n        logger.info(\"-\" * 40)\n\n        blocks_dir = self.output_base / \"memory_blocks\"\n        clusters_file = self.output_base / \"clustering_results\" / \"clustering_results.json\"\n\n        if not blocks_dir.exists():\n            logger.error(\"❌ Memory blocks directory not found.",
  "content": "#!/usr/bin/env python3\n\"\"\"\nMUSE Pantheon Universal Ingest Pipeline Orchestrator\nComplete pipeline: Ingest → Cluster → Assign Projects → Report\n\"\"\"\nimport sys\nimport pathlib\nimport argparse\nimport subprocess\nimport json\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import List, Dict, Any\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n\nclass PipelineOrchestrator:\n    \"\"\"Orchestrates the complete MUSE Pantheon ingest pipeline\"\"\"\n\n    def __init__(self, workspace_root: str):\n        self.workspace_root = pathlib.Path(workspace_root)\n        self.tools_dir = self.workspace_root / \"warden\" / \"tools\"\n        self.output_base = self.workspace_root / \"_work\" / \"pipeline_output\"\n        self.output_base.mkdir(parents=True, exist_ok=True)\n\n    def run_ingestion(self, roots: List[str], file_types: List[str] = None) -> bool:\n        \"\"\"Run the universal ingestion phase\"\"\"\n        logger.info(\"🚀 PHASE 1: Universal File Ingestion\")\n        logger.info(\"-\" * 40)\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"universal_ingest.py\"),\n            \"--roots\"\n        ] + roots + [\n            \"--output\", str(self.output_base / \"memory_blocks\")\n        ]\n\n        if file_types:\n            cmd.extend([\"--types\"] + file_types)\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"✅ Ingestion completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"❌ Ingestion failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"❌ Ingestion error: {e}\")\n            return False\n\n    def run_clustering(self) -> bool:\n        \"\"\"Run the clustering and embedding phase\"\"\"\n        logger.info(\"\\n🧠 PHASE 2: Clustering & Embeddings\")\n        logger.info(\"-\" * 40)\n\n        blocks_dir = self.output_base / \"memory_blocks\"\n        if not blocks_dir.exists() or not any(blocks_dir.glob(\"*.json\")):\n            logger.error(\"❌ Memory blocks directory not found or empty. Run ingestion first.\")\n            return False\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"cluster_embeddings.py\"),\n            \"--blocks-dir\", str(blocks_dir),\n            \"--output-dir\", str(self.output_base / \"clustering_results\")\n        ]\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"✅ Clustering completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"❌ Clustering failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"❌ Clustering error: {e}\")\n            return False\n\n    def run_project_assignment(self) -> bool:\n        \"\"\"Run the project assignment phase\"\"\"\n        logger.info(\"\\n🎯 PHASE 3: Project Assignment\")\n        logger.info(\"-\" * 40)\n\n        blocks_dir = self.output_base / \"memory_blocks\"\n        clusters_file = self.output_base / \"clustering_results\" / \"clustering_results.json\"\n\n        if not blocks_dir.exists():\n            logger.error(\"❌ Memory blocks directory not found. Run ingestion first.\")\n            return False\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"assign_projects.py\"),\n            \"--blocks-dir\", str(blocks_dir),\n            \"--output-dir\", str(self.output_base / \"project_assignments\")\n        ]\n\n        if clusters_file.exists():\n            cmd.extend([\"--clusters-file\", str(clusters_file)])\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"✅ Project assignment completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"❌ Project assignment failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"❌ Project assignment error: {e}\")\n            return False\n\n    def generate_final_report(self) -> Dict[str, Any]:\n        \"\"\"Generate comprehensive final report\"\"\"\n        logger.info(\"\\n📊 PHASE 4: Final Report Generation\")\n        logger.info(\"-\" * 40)\n\n        report = {\n            'pipeline_execution': {\n                'timestamp': datetime.now(timezone.utc).isoformat(),\n                'workspace': str(self.workspace_root),\n                'output_base': str(self.output_base)\n            },\n            'phases': {},\n            'summary': {}\n        }\n\n        # Check each phase output\n        phases = [\n            ('ingestion', 'memory_blocks'),\n            ('clustering', 'clustering_results'),\n            ('project_assignment', 'project_assignments')\n        ]\n\n        total_blocks = 0\n        for phase_name, dir_name in phases:\n            phase_dir = self.output_base / dir_name\n            if phase_dir.exists():\n                files = list(phase_dir.glob('*.json'))\n                report['phases'][phase_name] = {\n                    'status': 'completed',\n                    'output_count': len(files),\n                    'output_dir': str(phase_dir)\n                }\n                if phase_name == 'ingestion':\n                    total_blocks = len([f for f in files if f.name.startswith('memory_block_')])\n            else:\n                report['phases'][phase_name] = {'status': 'not_run'}\n\n        # Get clustering statistics\n        clustering_results_file = self.output_base / \"clustering_results\" / \"clustering_results.json\"\n        if clustering_results_file.exists():\n            try:\n                with open(clustering_results_file, 'r') as f:\n                    clustering_data = json.load(f)\n                    report['clustering_stats'] = {\n                        'n_clusters': clustering_data.get('clustering_results', {}).get('n_clusters', 0),\n                        'visualization_available': (self.output_base / \"clustering_results\" / \"cluster_visualization.html\").exists()\n                    }\n            except Exception as e:\n                logger.warning(f\"Failed to load clustering stats: {e}\")\n\n        # Get project assignment statistics\n        project_report_file = self.output_base / \"project_assignments\" / \"project_assignment_report.json\"\n        if project_report_file.exists():\n            try:\n                with open(project_report_file, 'r') as f:\n                    project_data = json.load(f)\n                    report['project_stats'] = project_data.get('project_assignment_summary', {})\n            except Exception as e:\n                logger.warning(f\"Failed to load project stats: {e}\")\n\n        report['summary'] = {\n            'total_memory_blocks': total_blocks,\n            'pipeline_status': 'completed' if total_blocks > 0 else 'failed'\n        }\n\n        self._create_human_readable_report(report)\n\n        return report\n\n    def _create_human_readable_report(self, report: Dict[str, Any]):\n        \"\"\"Create a human-readable summary file\"\"\"\n        summary_path = self.output_base / \"pipeline_summary.txt\"\n        with open(summary_path, 'w') as f:\n            f.write(\"MUSE Pantheon Pipeline Execution Summary\\n\")\n            f.write(\"=\" * 50 + \"\\n\\n\")\n            f.write(f\"Executed: {report['pipeline_execution']['timestamp']}\\n\")\n            f.write(f\"Workspace: {report['pipeline_execution']['workspace']}\\n\")\n            f.write(f\"Output Directory: {report['pipeline_execution']['output_base']}\\n\\n\")\n            \n            f.write(\"Phase Results:\\n\")\n            f.write(\"-\" * 14 + \"\\n\")\n            for phase, data in report['phases'].items():\n                f.write(f\"  {phase.title()}: {data['status']}\")\n                if 'output_count' in data:\n                    f.write(f\" ({data['output_count']} outputs)\")\n                f.write(\"\\n\")\n            \n            f.write(f\"\\nTotal Memory Blocks: {report['summary']['total_memory_blocks']}\\n\")\n            f.write(f\"Overall Status: {report['summary']['pipeline_status']}\\n\")\n            \n            # Add clustering info if available\n            if 'clustering_stats' in report:\n                f.write(f\"\\nClustering Results:\\n\")\n                f.write(f\"  Number of Clusters: {report['clustering_stats']['n_clusters']}\\n\")\n                f.write(f\"  Visualization Available: {report['clustering_stats']['visualization_available']}\\n\")\n            \n            # Add project info if available\n            if 'project_stats' in report:\n                f.write(f\"\\nProject Assignment:\\n\")\n                f.write(f\"  Total Projects: {report['project_stats'].get('total_projects', 'N/A')}\\n\")\n            \n            f.write(f\"\\nOutput Files:\\n\")\n            f.write(f\"  Memory Blocks: {self.output_base / 'memory_blocks'}\\n\")\n            f.write(f\"  Clustering Results: {self.output_base / 'clustering_results'}\\n\")\n            f.write(f\"  Project Assignments: {self.output_base / 'project_assignments'}\\n\")\n            f.write(f\"  Cluster Visualization: {self.output_base / 'clustering_results' / 'cluster_visualization.html'}\\n\")\n\n    def run_full_pipeline(self, roots: List[str], file_types: List[str] = None) -> bool:\n        \"\"\"Run the complete pipeline\"\"\"\n        logger.info(\"🎯 Starting MUSE Pantheon Universal Ingest Pipeline\")\n        logger.info(\"=\" * 60)\n        \n        success = True\n        \n        # Phase 1: Ingestion\n        if not self.run_ingestion(roots, file_types):\n            success = False\n            return success  # Early exit on ingestion failure\n        \n        # Phase 2: Clustering\n        if success and not self.run_clustering():\n            success = False\n            # Continue to other phases even if clustering fails\n            \n        # Phase 3: Project Assignment\n        if not self.run_project_assignment():\n            success = False\n            # Continue to reporting even if project assignment fails\n            \n        # Phase 4: Final Report\n        report = self.generate_final_report()\n        \n        logger.info(f\"\\n🎉 Pipeline {'completed successfully' if success else 'completed with errors'}\")\n        logger.info(f\"📁 Output directory: {self.output_base}\")\n        logger.info(f\"📄 Summary: {self.output_base / 'pipeline_summary.txt'}\")\n        \n        if report['summary']['total_memory_blocks'] > 0:\n            logger.info(f\"✅ Created {report['summary']['total_memory_blocks']} memory blocks\")\n            \n            # Show clustering info if available\n            if 'clustering_stats' in report:\n                logger.info(f\"🧠 Organized into {report['clustering_stats']['n_clusters']} semantic clusters\")\n                \n            # Show project info if available\n            if 'project_stats' in report:\n                logger.info(f\"🎯 Assigned to {report['project_stats'].get('total_projects', 'N/A')} projects\")\n                \n            logger.info(f\"🌐 Interactive visualization: {self.output_base / 'clustering_results' / 'cluster_visualization.html'}\")\n        \n        return success\n\n    def validate_environment(self) -> bool:\n        \"\"\"Validate that the environment is set up correctly\"\"\"\n        logger.info(\"🔍 Validating environment...\")\n        \n        # Check if tools directory exists\n        if not self.tools_dir.exists():\n            logger.error(f\"❌ Tools directory not found: {self.tools_dir}\")\n            return False\n            \n        # Check if individual tools exist\n        required_tools = [\n            \"universal_ingest.py\",\n            \"cluster_embeddings.py\", \n            \"assign_projects.py\"\n        ]\n        \n        for tool in required_tools:\n            tool_path = self.tools_dir / tool\n            if not tool_path.exists():\n                logger.error(f\"❌ Required tool not found: {tool_path}\")\n                return False\n                \n        # Check if common module exists\n        common_dir = self.workspace_root / \"common\"\n        if not common_dir.exists() or not (common_dir / \"memory_block.py\").exists():\n            logger.error(f\"❌ Common module not found: {common_dir / 'memory_block.py'}\")\n            return False\n            \n        logger.info(\"✅ Environment validation passed\")\n        return True\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    parser = argparse.ArgumentParser(description=\"MUSE Pantheon Universal Ingest Pipeline Orchestrator\")\n    parser.add_argument('--roots', nargs='+', required=True,\n                       help='Root directories to scan for files')\n    parser.add_argument('--types', nargs='+',\n                       help='File types to process (e.g., .txt .pdf .jpg)')\n    parser.add_argument('--workspace', default='.',\n                       help='Workspace root directory')\n    parser.add_argument('--validate-only', action='store_true',\n                       help='Only validate environment, do not run pipeline')\n\n    args = parser.parse_args()\n\n    # Initialize orchestrator\n    orchestrator = PipelineOrchestrator(args.workspace)\n\n    # Validate environment\n    if not orchestrator.validate_environment():\n        logger.error(\"❌ Environment validation failed\")\n        return 1\n\n    # If validation-only mode, exit here\n    if args.validate_only:\n        logger.info(\"✅ Environment validation successful\")\n        return 0\n\n    # Run full pipeline\n    success = orchestrator.run_full_pipeline(args.roots, args.types)\n\n    # Exit with appropriate code\n    return 0 if success else 1\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())",
  "topics": [
    "clustering",
    "return",
    "pipeline",
    "py",
    "false",
    "full",
    "run",
    "phase",
    "self.output_base"
  ],
  "skills": [
    "nano_warden_universal_ingest_py.py",
    "nano_warden_code_analyzer.py",
    "nano_warden_dependency_tracker.py",
    "nano_warden_memory_system.py"
  ],
  "date": "2025-09-17",
  "project": "muse.pantheon",
  "archetype": "Alchemist",
  "created_at": "2025-09-17T18:19:13.042717+00:00",
  "source_path": "warden/tools/run_full_pipeline.py",
  "file_type": ".py",
  "pii_redacted": false,
  "consent_logged": true,
  "ethics_review": "passed",
  "links": [],
  "parent_blocks": [],
  "metadata": {
    "file_size": 13917,
    "source": "file_ingest",
    "validation_status": "passed",
    "project_assigned_by": "auto_classifier",
    "original_project": "muse.pantheon",
    "project_hierarchy": {
      "domain": "muse",
      "category": "pantheon",
      "subcategory": "core",
      "description": "Core MUSE Pantheon memory system"
    }
  }
}