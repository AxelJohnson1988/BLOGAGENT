{
  "id_hash": "99264cdb873f",
  "summary": "#!/usr/bin/env python3\n\"\"\"\nUniversal File Ingest System for MUSE Pantheon\nProcesses any file format and converts to MemoryBlocks\n\"\"\"\nimport sys\nimport argparse\nimport json\nimport logging\nfrom pathlib ...",
  "content": "#!/usr/bin/env python3\n\"\"\"\nUniversal File Ingest System for MUSE Pantheon\nProcesses any file format and converts to MemoryBlocks\n\"\"\"\nimport sys\nimport argparse\nimport json\nimport logging\nfrom pathlib import Path\nfrom typing import List, Dict, Any, Optional\nimport mimetypes\nimport zipfile\nimport hashlib\n\n# Add common directory to path for imports\nsys.path.append(str(Path(__file__).parent.parent.parent / \"common\"))\nfrom memory_block import MemoryBlock, MemoryBlockFactory\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n\nclass UniversalFileProcessor:\n    \"\"\"Processes files of any format into MemoryBlocks.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the file processor.\"\"\"\n        self.supported_types = {\n            '.txt', '.md', '.py', '.js', '.ts', '.json', '.csv', '.xml', '.html',\n            '.pdf', '.doc', '.docx', '.rtf',\n            '.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff',\n            '.mp4', '.avi', '.mov', '.wmv', '.flv', '.mp3', '.wav', '.m4a',\n            '.zip', '.tar', '.gz', '.rar'\n        }\n        \n    def can_process(self, filepath: Path) -> bool:\n        \"\"\"Check if file can be processed.\"\"\"\n        return filepath.suffix.lower() in self.supported_types\n    \n    def process_file(self, filepath: Path) -> Optional[MemoryBlock]:\n        \"\"\"Process a single file into a MemoryBlock.\"\"\"\n        try:\n            if not filepath.exists() or not filepath.is_file():\n                logger.warning(f\"File not found or not a file: {filepath}\")\n                return None\n                \n            if not self.can_process(filepath):\n                logger.warning(f\"Unsupported file type: {filepath.suffix}\")\n                return None\n            \n            # Extract content based on file type\n            content = self._extract_content(filepath)\n            if not content:\n                logger.warning(f\"No content extracted from: {filepath}\")\n                return None\n            \n            # Create MemoryBlock\n            memory_block = MemoryBlockFactory.create_from_file(filepath, content)\n            \n            # Validate and set status\n            if memory_block.validate():\n                memory_block.metadata[\"validation_status\"] = \"passed\"\n                logger.info(f\"Successfully processed: {filepath.name}\")\n            else:\n                memory_block.metadata[\"validation_status\"] = \"failed\"\n                logger.warning(f\"Validation failed for: {filepath.name}\")\n            \n            return memory_block\n            \n        except Exception as e:\n            logger.error(f\"Error processing {filepath}: {str(e)}\")\n            return None\n    \n    def _extract_content(self, filepath: Path) -> str:\n        \"\"\"Extract content from file based on type.\"\"\"\n        file_ext = filepath.suffix.lower()\n        \n        try:\n            if file_ext in {'.txt', '.md', '.py', '.js', '.ts', '.json', '.csv', '.xml', '.html'}:\n                return self._extract_text_content(filepath)\n            elif file_ext == '.pdf':\n                return self._extract_pdf_content(filepath)\n            elif file_ext in {'.jpg', '.jpeg', '.png', '.gif', '.bmp', '.tiff'}:\n                return self._extract_image_content(filepath)\n            elif file_ext in {'.mp4', '.avi', '.mov', '.wmv', '.flv'}:\n                return self._extract_video_content(filepath)\n            elif file_ext in {'.mp3', '.wav', '.m4a'}:\n                return self._extract_audio_content(filepath)\n            elif file_ext in {'.zip', '.tar', '.gz', '.rar'}:\n                return self._extract_archive_content(filepath)\n            else:\n                # Fallback to text extraction\n                return self._extract_text_content(filepath)\n                \n        except Exception as e:\n            logger.error(f\"Content extraction failed for {filepath}: {str(e)}\")\n            return f\"Content extraction failed: {str(e)}\"\n    \n    def _extract_text_content(self, filepath: Path) -> str:\n        \"\"\"Extract text content from text-based files.\"\"\"\n        try:\n            # Try different encodings\n            encodings = ['utf-8', 'latin-1', 'cp1252', 'ascii']\n            \n            for encoding in encodings:\n                try:\n                    with open(filepath, 'r', encoding=encoding) as f:\n                        content = f.read()\n                    return content\n                except UnicodeDecodeError:\n                    continue\n            \n            # If all encodings fail, read as binary and decode with errors='ignore'\n            with open(filepath, 'rb') as f:\n                content = f.read().decode('utf-8', errors='ignore')\n            return content\n            \n        except Exception as e:\n            return f\"Text extraction failed: {str(e)}\"\n    \n    def _extract_pdf_content(self, filepath: Path) -> str:\n        \"\"\"Extract text from PDF files.\"\"\"\n        try:\n            # Try to import PDF processing libraries\n            try:\n                import PyPDF2\n                with open(filepath, 'rb') as f:\n                    reader = PyPDF2.PdfReader(f)\n                    text = \"\"\n                    for page in reader.pages:\n                        text += page.extract_text() + \"\\n\"\n                return text\n            except ImportError:\n                pass\n            \n            try:\n                import pdfplumber\n                with pdfplumber.open(filepath) as pdf:\n                    text = \"\"\n                    for page in pdf.pages:\n                        text += page.extract_text() + \"\\n\"\n                return text\n            except ImportError:\n                pass\n            \n            # Fallback: return file metadata\n            return f\"PDF file: {filepath.name} (size: {filepath.stat().st_size} bytes)\"\n            \n        except Exception as e:\n            return f\"PDF extraction failed: {str(e)}\"\n    \n    def _extract_image_content(self, filepath: Path) -> str:\n        \"\"\"Extract metadata and OCR from images.\"\"\"\n        try:\n            # Try OCR extraction\n            try:\n                import pytesseract\n                from PIL import Image\n                \n                image = Image.open(filepath)\n                text = pytesseract.image_to_string(image)\n                \n                if text.strip():\n                    return f\"OCR extracted text: {text}\"\n                else:\n                    return f\"Image file: {filepath.name} (size: {filepath.stat().st_size} bytes)\"\n                    \n            except ImportError:\n                pass\n            \n            # Fallback: return image metadata\n            try:\n                from PIL import Image\n                with Image.open(filepath) as img:\n                    return f\"Image: {filepath.name}, format: {img.format}, size: {img.size}, mode: {img.mode}\"\n            except ImportError:\n                pass\n            \n            return f\"Image file: {filepath.name} (size: {filepath.stat().st_size} bytes)\"\n            \n        except Exception as e:\n            return f\"Image processing failed: {str(e)}\"\n    \n    def _extract_video_content(self, filepath: Path) -> str:\n        \"\"\"Extract metadata from video files.\"\"\"\n        try:\n            # Try to extract video metadata\n            try:\n                import cv2\n                cap = cv2.VideoCapture(str(filepath))\n                fps = cap.get(cv2.CAP_PROP_FPS)\n                frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n                duration = frame_count / fps if fps > 0 else 0\n                width = cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n                height = cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n                cap.release()\n                \n                return f\"Video: {filepath.name}, duration: {duration:.2f}s, resolution: {int(width)}x{int(height)}, fps: {fps}\"\n            except ImportError:\n                pass\n            \n            # Fallback: return basic file info\n            return f\"Video file: {filepath.name} (size: {filepath.stat().st_size} bytes)\"\n            \n        except Exception as e:\n            return f\"Video processing failed: {str(e)}\"\n    \n    def _extract_audio_content(self, filepath: Path) -> str:\n        \"\"\"Extract metadata from audio files.\"\"\"\n        try:\n            # Try to extract audio metadata\n            try:\n                import mutagen\n                audiofile = mutagen.File(filepath)\n                if audiofile:\n                    info = audiofile.info\n                    return f\"Audio: {filepath.name}, duration: {info.length:.2f}s, bitrate: {info.bitrate}\"\n            except ImportError:\n                pass\n            \n            # Fallback: return basic file info\n            return f\"Audio file: {filepath.name} (size: {filepath.stat().st_size} bytes)\"\n            \n        except Exception as e:\n            return f\"Audio processing failed: {str(e)}\"\n    \n    def _extract_archive_content(self, filepath: Path) -> str:\n        \"\"\"Extract file list from archives.\"\"\"\n        try:\n            if filepath.suffix.lower() == '.zip':\n                with zipfile.ZipFile(filepath, 'r') as zip_file:\n                    file_list = zip_file.namelist()\n                    return f\"ZIP archive: {filepath.name}, contains {len(file_list)} files: {', '.join(file_list[:10])}{'...' if len(file_list) > 10 else ''}\"\n            else:\n                return f\"Archive file: {filepath.name} (size: {filepath.stat().st_size} bytes)\"\n                \n        except Exception as e:\n            return f\"Archive processing failed: {str(e)}\"\n\n\nclass UniversalIngest:\n    \"\"\"Main ingest orchestrator.\"\"\"\n    \n    def __init__(self, output_dir: Path):\n        \"\"\"Initialize the ingest system.\"\"\"\n        self.output_dir = Path(output_dir)\n        self.output_dir.mkdir(parents=True, exist_ok=True)\n        self.processor = UniversalFileProcessor()\n        self.stats = {\n            'processed': 0,\n            'failed': 0,\n            'skipped': 0,\n            'total_files': 0\n        }\n    \n    def ingest_directory(self, root_dir: Path, file_types: List[str] = None) -> List[MemoryBlock]:\n        \"\"\"Ingest all files from a directory.\"\"\"\n        logger.info(f\"Starting ingest of directory: {root_dir}\")\n        \n        memory_blocks = []\n        \n        # Get all files\n        if file_types:\n            files = []\n            for file_type in file_types:\n                files.extend(root_dir.rglob(f\"*{file_type}\"))\n        else:\n            files = [f for f in root_dir.rglob(\"*\") if f.is_file()]\n        \n        self.stats['total_files'] = len(files)\n        logger.info(f\"Found {len(files)} files to process\")\n        \n        for filepath in files:\n            try:\n                memory_block = self.processor.process_file(filepath)\n                \n                if memory_block:\n                    # Save the memory block\n                    output_path = memory_block.save(self.output_dir)\n                    memory_blocks.append(memory_block)\n                    self.stats['processed'] += 1\n                    \n                    if self.stats['processed'] % 100 == 0:\n                        logger.info(f\"Processed {self.stats['processed']} files...\")\n                else:\n                    self.stats['failed'] += 1\n                    \n            except Exception as e:\n                logger.error(f\"Failed to process {filepath}: {str(e)}\")\n                self.stats['failed'] += 1\n        \n        self._save_ingest_report(memory_blocks)\n        logger.info(f\"Ingest complete. Processed: {self.stats['processed']}, Failed: {self.stats['failed']}\")\n        \n        return memory_blocks\n    \n    def _save_ingest_report(self, memory_blocks: List[MemoryBlock]):\n        \"\"\"Save ingest report with statistics.\"\"\"\n        report = {\n            'ingest_stats': self.stats,\n            'memory_blocks_created': len(memory_blocks),\n            'output_directory': str(self.output_dir),\n            'block_summaries': [\n                {\n                    'id_hash': block.id_hash,\n                    'summary': block.summary,\n                    'archetype': block.archetype,\n                    'project': block.project,\n                    'source_path': block.source_path\n                }\n                for block in memory_blocks[:50]  # First 50 blocks\n            ]\n        }\n        \n        report_path = self.output_dir / \"ingest_report.json\"\n        with open(report_path, 'w') as f:\n            json.dump(report, f, indent=2)\n        \n        logger.info(f\"Ingest report saved to: {report_path}\")\n\n\ndef main():\n    \"\"\"Main entry point.\"\"\"\n    parser = argparse.ArgumentParser(description=\"Universal File Ingest for MUSE Pantheon\")\n    parser.add_argument('--roots', nargs='+', required=True,\n                       help='Root directories to scan for files')\n    parser.add_argument('--types', nargs='+',\n                       help='File types to process (e.g., .txt .pdf .jpg)')\n    parser.add_argument('--output', required=True,\n                       help='Output directory for memory blocks')\n    \n    args = parser.parse_args()\n    \n    # Initialize ingest system\n    ingest_system = UniversalIngest(args.output)\n    \n    # Process each root directory\n    all_blocks = []\n    for root in args.roots:\n        root_path = Path(root)\n        if root_path.exists():\n            blocks = ingest_system.ingest_directory(root_path, args.types)\n            all_blocks.extend(blocks)\n        else:\n            logger.warning(f\"Root directory does not exist: {root}\")\n    \n    logger.info(f\"Total memory blocks created: {len(all_blocks)}\")\n    return 0\n\n\nif __name__ == \"__main__\":\n    sys.exit(main())",
  "topics": [
    "return",
    "try:",
    "py",
    "ingest",
    "file",
    "universal",
    "except",
    "import"
  ],
  "skills": [
    "nano_warden_universal_ingest_py.py",
    "nano_warden_code_analyzer.py",
    "nano_warden_dependency_tracker.py",
    "nano_warden_memory_system.py"
  ],
  "date": "2025-09-17",
  "project": "muse.pantheon",
  "archetype": "Alchemist",
  "created_at": "2025-09-17T18:19:13.044540+00:00",
  "source_path": "warden/tools/universal_ingest.py",
  "file_type": ".py",
  "pii_redacted": false,
  "consent_logged": true,
  "ethics_review": "passed",
  "links": [],
  "parent_blocks": [],
  "metadata": {
    "file_size": 13742,
    "source": "file_ingest",
    "validation_status": "passed",
    "project_assigned_by": "auto_classifier",
    "original_project": "muse.pantheon",
    "project_hierarchy": {
      "domain": "muse",
      "category": "pantheon",
      "subcategory": "core",
      "description": "Core MUSE Pantheon memory system"
    }
  }
}