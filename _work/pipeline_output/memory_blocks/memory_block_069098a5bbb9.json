{
  "id_hash": "069098a5bbb9",
  "summary": "# MUSE Pantheon Universal Ingest Pipeline\n\n## Overview\n\nThe MUSE Pantheon Universal Ingest Pipeline is a comprehensive system for converting any file format into structured, semantic MemoryBlocks. It processes files, extracts content, generates embeddings, clusters similar content, and assigns project hierarchies - all while maintaining ethics tracking and consent logging.\n\n## Architecture\n\n### Core Components\n\n1.",
  "content": "# MUSE Pantheon Universal Ingest Pipeline\n\n## Overview\n\nThe MUSE Pantheon Universal Ingest Pipeline is a comprehensive system for converting any file format into structured, semantic MemoryBlocks. It processes files, extracts content, generates embeddings, clusters similar content, and assigns project hierarchies - all while maintaining ethics tracking and consent logging.\n\n## Architecture\n\n### Core Components\n\n1. **MemoryBlock System** (`common/memory_block.py`)\n   - Atomic, immutable, sovereign, and semantic memory blocks\n   - 12 archetypes: Discoverer, Guardian, Alchemist, Oracle, Sage, Shaman, Visionary, Architect, Weaver, Navigator, Storyteller, Scribe\n   - Built-in ethics tracking: PII redaction, consent logging, validation\n\n2. **Universal Ingest** (`warden/tools/universal_ingest.py`)\n   - Processes any file format: text, code, images, PDFs, videos, archives\n   - OCR for images, PDF parsing, metadata extraction\n   - Graceful degradation when dependencies are missing\n\n3. **Clustering & Embeddings** (`warden/tools/cluster_embeddings.py`)\n   - TF-IDF vectorization with custom preprocessing\n   - K-means clustering with automatic cluster detection\n   - Interactive Plotly visualization with PCA projection\n\n4. **Project Assignment** (`warden/tools/assign_projects.py`)\n   - Content-based project classification\n   - Archetype-aware assignment\n   - Hierarchical project organization\n\n5. **Pipeline Orchestrator** (`warden/tools/run_full_pipeline.py`)\n   - Coordinates all phases with error handling\n   - Comprehensive reporting and statistics\n   - Environment validation\n\n## Installation\n\n### Prerequisites\n\nThe pipeline works with just Python standard library, but additional features require:\n\n```bash\n# Optional: For enhanced processing\npip install pytesseract pillow  # OCR for images\npip install PyPDF2 pdfplumber   # PDF processing\npip install opencv-python       # Video metadata\npip install mutagen            # Audio metadata\n```\n\n### Setup\n\n1. Clone the repository\n2. Ensure Python 3.7+ is available\n3. Make scripts executable: `chmod +x run_pipeline.py warden/tools/*.py`\n\n## Usage\n\n### Quick Start\n\n```bash\n# Process current directory with common file types\n./run_pipeline.py --scan-root . --apply\n\n# Process specific directory with custom types\n./run_pipeline.py --scan-root /path/to/files --types .py .md .json --apply\n\n# Dry run to see what would be processed\n./run_pipeline.py --scan-root /path/to/files\n```\n\n### Advanced Usage\n\n```bash\n# Full pipeline with all options\npython warden/tools/run_full_pipeline.py \\\n  --roots /path/to/files1 /path/to/files2 \\\n  --types .py .md .txt .json .jpg .pdf \\\n  --workspace /custom/workspace\n\n# Individual phases\npython warden/tools/universal_ingest.py --roots /path --output /output\npython warden/tools/cluster_embeddings.py --blocks-dir /blocks --output-dir /clusters\npython warden/tools/assign_projects.py --blocks-dir /blocks --output-dir /projects\n\n# Environment validation\npython warden/tools/run_full_pipeline.py --validate-only\n```\n\n### Supported File Types\n\n- **Text**: .txt, .md, .py, .js, .ts, .json, .csv, .xml, .html\n- **Documents**: .pdf, .doc, .docx, .rtf\n- **Images**: .jpg, .jpeg, .png, .gif, .bmp, .tiff (with OCR)\n- **Media**: .mp4, .avi, .mov, .mp3, .wav (metadata extraction)\n- **Archives**: .zip, .tar, .gz, .rar (file listing)\n\n## Output Structure\n\n```\n_work/pipeline_output/\n├── memory_blocks/                    # Individual MemoryBlock JSON files\n│   ├── memory_block_abc123.json\n│   ├── memory_block_def456.json\n│   └── ingest_report.json           # Ingestion statistics\n├── clustering_results/              # Semantic clustering results\n│   ├── clustering_results.json     # Cluster assignments\n│   └── cluster_visualization.html  # Interactive visualization\n├── project_assignments/             # Project assignment results\n│   ├── memory_block_abc123.json    # Updated blocks with projects\n│   ├── project_assignment_report.json\n│   └── project_assignment_summary.txt\n└── pipeline_summary.txt             # Overall execution summary\n```\n\n## MemoryBlock Schema\n\n```json\n{\n  \"id_hash\": \"abc123def456\",\n  \"summary\": \"Brief description of content\",\n  \"content\": \"Full extracted content\",\n  \"topics\": [\"keyword1\", \"keyword2\"],\n  \"skills\": [\"nano_warden_processing.py\"],\n  \"date\": \"2024-12-17\",\n  \"project\": \"muse.pantheon\",\n  \"archetype\": \"Guardian\",\n  \"created_at\": \"2024-12-17T10:30:00Z\",\n  \"source_path\": \"/path/to/original/file.py\",\n  \"file_type\": \".py\",\n  \"pii_redacted\": false,\n  \"consent_logged\": true,\n  \"ethics_review\": \"passed\",\n  \"links\": [],\n  \"parent_blocks\": [],\n  \"metadata\": {\n    \"file_size\": 1024,\n    \"source\": \"file_ingest\",\n    \"validation_status\": \"passed\"\n  }\n}\n```\n\n## Project Classification\n\nThe system automatically assigns projects based on content analysis:\n\n### Project Categories\n\n- **muse.pantheon**: Core memory system, archetypes, foundational components\n- **blog.agent**: Content generation, writing, publishing\n- **warden.system**: Security, monitoring, ethics enforcement\n- **ai.assistant**: AI agents, assistants, interaction systems\n- **legal.documentation**: Contracts, compliance, legal content\n- **data.analytics**: Data analysis, reporting, insights\n- **creative.content**: Design, media, artistic content\n- **development.tools**: Code tools, utilities, automation\n\n### Archetype-Project Mapping\n\n- **Guardian/Warden**: Security and monitoring systems\n- **Oracle/Sage**: Knowledge and AI systems\n- **Scribe/Storyteller**: Content and documentation\n- **Alchemist/Architect**: Development and building\n- **Visionary**: Creative and design systems\n\n## Error Handling\n\nThe pipeline is designed for resilience:\n\n- **Individual file failures** don't stop processing\n- **Missing dependencies** result in graceful degradation\n- **Comprehensive logging** with error details\n- **Partial results** are still useful and saved\n\n## Integration\n\n### Loading MemoryBlocks\n\n```python\nimport json\nfrom pathlib import Path\nfrom common.memory_block import MemoryBlock\n\n# Load all memory blocks\nblocks = []\nfor json_file in Path(\"_work/pipeline_output/memory_blocks\").glob(\"memory_block_*.json\"):\n    with open(json_file) as f:\n        data = json.load(f)\n        block = MemoryBlock.from_dict(data)\n        blocks.append(block)\n```\n\n### Querying by Project\n\n```python\n# Filter by project\nmuse_blocks = [b for b in blocks if b.project == \"muse.pantheon\"]\n\n# Filter by archetype\nguardian_blocks = [b for b in blocks if b.archetype == \"Guardian\"]\n\n# Filter by topics\nmemory_blocks = [b for b in blocks if \"memory\" in b.topics]\n```\n\n### Using Clustering Results\n\n```python\n# Load clustering results\nwith open(\"_work/pipeline_output/clustering_results/clustering_results.json\") as f:\n    clustering = json.load(f)\n\n# Get blocks in same cluster\ncluster_0_blocks = [\n    blocks[i] for i, label in enumerate(clustering[\"clustering_results\"][\"cluster_labels\"])\n    if label == 0\n]\n```\n\n## Troubleshooting\n\n### Common Issues\n\n1. **No memory blocks created**\n   - Check if input directory exists and contains supported files\n   - Verify file permissions\n   - Check logs for encoding errors\n\n2. **Clustering fails**\n   - Ensure at least 2 memory blocks were created\n   - Check for extremely short content (less than 10 words)\n\n3. **Missing visualizations**\n   - Install optional dependencies for better processing\n   - Check browser compatibility for HTML visualization\n\n4. **Permission errors**\n   - Ensure write permissions to output directory\n   - Check that scripts are executable\n\n### Debugging\n\n```bash\n# Enable verbose logging\nexport PYTHONPATH=/path/to/BLOGAGENT:$PYTHONPATH\npython -m logging DEBUG warden/tools/run_full_pipeline.py --roots /path\n\n# Validate environment\npython warden/tools/run_full_pipeline.py --validate-only\n\n# Test with single file type\npython warden/tools/universal_ingest.py --roots /path --types .txt --output /tmp/test\n```\n\n## Performance\n\n### Optimization Tips\n\n- **Limit file types** to reduce processing time\n- **Use SSD storage** for better I/O performance\n- **Increase RAM** for large document processing\n- **Process in batches** for very large datasets\n\n### Scalability\n\n- **Memory usage**: ~1MB per 1000 files processed\n- **Processing speed**: ~100 files/second for text files\n- **Storage**: ~10KB per MemoryBlock on average\n\n## Contributing\n\n### Adding New File Processors\n\n1. Extend `UniversalFileProcessor._extract_content()` in `universal_ingest.py`\n2. Add file extension to `supported_types`\n3. Implement extraction logic with graceful error handling\n4. Test with sample files\n\n### Extending Project Classification\n\n1. Add new project patterns to `ProjectClassifier.project_patterns`\n2. Update archetype mappings as needed\n3. Test classification accuracy with sample content\n\n### Custom Archetypes\n\n1. Add to `MemoryBlockFactory.ARCHETYPES` in `memory_block.py`\n2. Update archetype determination logic\n3. Adjust project mappings accordingly\n\n## License\n\nThis project is part of the MUSE Pantheon system for AI agent memory and knowledge management.",
  "topics": [
    "blocks",
    "pipeline",
    "file",
    "docs",
    "python",
    "content",
    "project",
    "md"
  ],
  "skills": [
    "nano_warden_universal_ingest_md.py",
    "nano_warden_dependency_tracker.py",
    "nano_warden_memory_system.py"
  ],
  "date": "2025-09-17",
  "project": "general.development",
  "archetype": "Scribe",
  "created_at": "2025-09-17T18:19:13.045711+00:00",
  "source_path": "PIPELINE_DOCS.md",
  "file_type": ".md",
  "pii_redacted": false,
  "consent_logged": true,
  "ethics_review": "passed",
  "links": [],
  "parent_blocks": [],
  "metadata": {
    "file_size": 9089,
    "source": "file_ingest",
    "validation_status": "passed"
  }
}