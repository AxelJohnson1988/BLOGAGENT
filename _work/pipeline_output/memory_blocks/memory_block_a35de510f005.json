{
  "id_hash": "a35de510f005",
  "summary": "#!/usr/bin/env python3\n\"\"\"\nMUSE Pantheon MemoryBlock Schema\nCore data structure for immutable, atomic, sovereign, and semantic memory blocks.\n\"\"\"\nimport hashlib\nimport json\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\n\n@dataclass\nclass MemoryBlock:\n    \"\"\"\n    Atomic, immutable, sovereign, and semantic memory block.\n    Core data structure for the MUSE Pantheon system.\n    \"\"\"\n    # Core identification\n    id_hash: str\n    summary: str\n    content: str\n    \n    # Metadata\n    topics: List[str]\n    skills: List[str]\n    date: str\n    project: str\n    archetype: str\n    \n    # System fields\n    created_at: str = \"\"\n    source_path: Optional[str] = None\n    file_type: Optional[str] = None\n    \n    # Ethics and consent tracking\n    pii_redacted: bool = False\n    consent_logged: bool = True\n    ethics_review: str = \"passed\"\n    \n    # Relationships\n    links: List[str] = None\n    parent_blocks: List[str] = None\n    \n    # Additional metadata\n    metadata: Dict[str, Any] = None\n    \n    def __post_init__(self):\n        \"\"\"Initialize default values and validate required fields.\"\"\"\n        if self.links is None:\n            self.links = []\n        if self.parent_blocks is None:\n            self.parent_blocks = []\n        if self.metadata is None:\n            self.metadata = {}\n            \n        # Generate hash if not provided\n        if not self.id_hash:\n            self.id_hash = self.generate_hash()\n            \n        # Set created_at if not provided\n        if not self.created_at:\n            self.created_at = datetime.now(timezone.utc).isoformat()\n\n    def generate_hash(self) -> str:\n        \"\"\"Generate SHA256 hash from content and metadata.\"\"\"\n        content_for_hash = f\"{self.summary}:{self.content}:{self.date}\"\n        return hashlib.sha256(content_for_hash.encode()).hexdigest()[:12]\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        return asdict(self)\n\n    def to_json(self) -> str:\n        \"\"\"Convert to JSON string.\"\"\"\n        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'MemoryBlock':\n        \"\"\"Create MemoryBlock from dictionary.\"\"\"\n        return cls(**data)\n\n    @classmethod\n    def from_json(cls, json_str: str) -> 'MemoryBlock':\n        \"\"\"Create MemoryBlock from JSON string.\"\"\"\n        return cls.from_dict(json.loads(json_str))\n\n    def save(self, output_dir: Path) -> Path:\n        \"\"\"Save memory block to file.\"\"\"\n        output_dir.mkdir(parents=True, exist_ok=True)\n        filename = f\"memory_block_{self.id_hash}.json\"\n        filepath = output_dir / filename\n        \n        with open(filepath, 'w', encoding='utf-8') as f:\n            f.write(self.to_json())\n            \n        return filepath\n\n    def validate(self) -> bool:\n        \"\"\"Validate memory block structure and content.\"\"\"\n        required_fields = ['id_hash', 'summary', 'content', 'topics', 'date', 'archetype']\n        for field in required_fields:\n            if not getattr(self, field):\n                return False\n        return True\n\n\nclass MemoryBlockFactory:\n    \"\"\"Factory for creating MemoryBlocks from various sources.\"\"\"\n    \n    ARCHETYPES = [\n        \"Discoverer\", \"Guardian\", \"Alchemist\", \"Oracle\", \"Sage\", \"Shaman\",\n        \"Visionary\", \"Architect\", \"Weaver\", \"Navigator\", \"Storyteller\", \"Scribe\"\n    ]\n    \n    @classmethod\n    def create_from_file(cls, filepath: Path, content: str, summary: str = None) -> MemoryBlock:\n        \"\"\"Create MemoryBlock from file content.\"\"\"\n        # Generate summary if not provided\n        if not summary:\n            summary = cls._generate_summary(content, filepath)\n        \n        # Extract topics from content\n        topics = cls._extract_topics(content, filepath)\n        \n        # Determine archetype based on content type\n        archetype = cls._determine_archetype(filepath, content)\n        \n        # Generate skills based on file type and content\n        skills = cls._generate_skills(filepath, content)\n        \n        # Determine project based on path and content\n        project = cls._determine_project(filepath, content)\n        \n        return MemoryBlock(\n            id_hash=\"\",  # Will be generated in __post_init__\n            summary=summary,\n            content=content,\n            topics=topics,\n            skills=skills,\n            date=datetime.now().strftime(\"%Y-%m-%d\"),\n            project=project,\n            archetype=archetype,\n            source_path=str(filepath),\n            file_type=filepath.suffix.lower(),\n            metadata={\n                \"file_size\": filepath.stat().st_size if filepath.exists() else 0,\n                \"source\": \"file_ingest\",\n                \"validation_status\": \"pending\"\n            }\n        )\n    \n    @classmethod\n    def _generate_summary(cls, content: str, filepath: Path) -> str:\n        \"\"\"Generate summary from content.\"\"\"\n        # Simple summary generation - first few sentences or truncated content\n        sentences = content.split('. ')\n        if len(sentences) > 2:\n            return '.",
  "content": "#!/usr/bin/env python3\n\"\"\"\nMUSE Pantheon MemoryBlock Schema\nCore data structure for immutable, atomic, sovereign, and semantic memory blocks.\n\"\"\"\nimport hashlib\nimport json\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\n\n@dataclass\nclass MemoryBlock:\n    \"\"\"\n    Atomic, immutable, sovereign, and semantic memory block.\n    Core data structure for the MUSE Pantheon system.\n    \"\"\"\n    # Core identification\n    id_hash: str\n    summary: str\n    content: str\n    \n    # Metadata\n    topics: List[str]\n    skills: List[str]\n    date: str\n    project: str\n    archetype: str\n    \n    # System fields\n    created_at: str = \"\"\n    source_path: Optional[str] = None\n    file_type: Optional[str] = None\n    \n    # Ethics and consent tracking\n    pii_redacted: bool = False\n    consent_logged: bool = True\n    ethics_review: str = \"passed\"\n    \n    # Relationships\n    links: List[str] = None\n    parent_blocks: List[str] = None\n    \n    # Additional metadata\n    metadata: Dict[str, Any] = None\n    \n    def __post_init__(self):\n        \"\"\"Initialize default values and validate required fields.\"\"\"\n        if self.links is None:\n            self.links = []\n        if self.parent_blocks is None:\n            self.parent_blocks = []\n        if self.metadata is None:\n            self.metadata = {}\n            \n        # Generate hash if not provided\n        if not self.id_hash:\n            self.id_hash = self.generate_hash()\n            \n        # Set created_at if not provided\n        if not self.created_at:\n            self.created_at = datetime.now(timezone.utc).isoformat()\n\n    def generate_hash(self) -> str:\n        \"\"\"Generate SHA256 hash from content and metadata.\"\"\"\n        content_for_hash = f\"{self.summary}:{self.content}:{self.date}\"\n        return hashlib.sha256(content_for_hash.encode()).hexdigest()[:12]\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        return asdict(self)\n\n    def to_json(self) -> str:\n        \"\"\"Convert to JSON string.\"\"\"\n        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'MemoryBlock':\n        \"\"\"Create MemoryBlock from dictionary.\"\"\"\n        return cls(**data)\n\n    @classmethod\n    def from_json(cls, json_str: str) -> 'MemoryBlock':\n        \"\"\"Create MemoryBlock from JSON string.\"\"\"\n        return cls.from_dict(json.loads(json_str))\n\n    def save(self, output_dir: Path) -> Path:\n        \"\"\"Save memory block to file.\"\"\"\n        output_dir.mkdir(parents=True, exist_ok=True)\n        filename = f\"memory_block_{self.id_hash}.json\"\n        filepath = output_dir / filename\n        \n        with open(filepath, 'w', encoding='utf-8') as f:\n            f.write(self.to_json())\n            \n        return filepath\n\n    def validate(self) -> bool:\n        \"\"\"Validate memory block structure and content.\"\"\"\n        required_fields = ['id_hash', 'summary', 'content', 'topics', 'date', 'archetype']\n        for field in required_fields:\n            if not getattr(self, field):\n                return False\n        return True\n\n\nclass MemoryBlockFactory:\n    \"\"\"Factory for creating MemoryBlocks from various sources.\"\"\"\n    \n    ARCHETYPES = [\n        \"Discoverer\", \"Guardian\", \"Alchemist\", \"Oracle\", \"Sage\", \"Shaman\",\n        \"Visionary\", \"Architect\", \"Weaver\", \"Navigator\", \"Storyteller\", \"Scribe\"\n    ]\n    \n    @classmethod\n    def create_from_file(cls, filepath: Path, content: str, summary: str = None) -> MemoryBlock:\n        \"\"\"Create MemoryBlock from file content.\"\"\"\n        # Generate summary if not provided\n        if not summary:\n            summary = cls._generate_summary(content, filepath)\n        \n        # Extract topics from content\n        topics = cls._extract_topics(content, filepath)\n        \n        # Determine archetype based on content type\n        archetype = cls._determine_archetype(filepath, content)\n        \n        # Generate skills based on file type and content\n        skills = cls._generate_skills(filepath, content)\n        \n        # Determine project based on path and content\n        project = cls._determine_project(filepath, content)\n        \n        return MemoryBlock(\n            id_hash=\"\",  # Will be generated in __post_init__\n            summary=summary,\n            content=content,\n            topics=topics,\n            skills=skills,\n            date=datetime.now().strftime(\"%Y-%m-%d\"),\n            project=project,\n            archetype=archetype,\n            source_path=str(filepath),\n            file_type=filepath.suffix.lower(),\n            metadata={\n                \"file_size\": filepath.stat().st_size if filepath.exists() else 0,\n                \"source\": \"file_ingest\",\n                \"validation_status\": \"pending\"\n            }\n        )\n    \n    @classmethod\n    def _generate_summary(cls, content: str, filepath: Path) -> str:\n        \"\"\"Generate summary from content.\"\"\"\n        # Simple summary generation - first few sentences or truncated content\n        sentences = content.split('. ')\n        if len(sentences) > 2:\n            return '. '.join(sentences[:2]) + '.'\n        elif len(content) > 200:\n            return content[:200] + \"...\"\n        else:\n            return content\n    \n    @classmethod\n    def _extract_topics(cls, content: str, filepath: Path) -> List[str]:\n        \"\"\"Extract topics from content and filename.\"\"\"\n        topics = []\n        \n        # Add file type as topic\n        if filepath.suffix:\n            topics.append(filepath.suffix.lower().replace('.', ''))\n        \n        # Add filename parts as topics\n        name_parts = filepath.stem.lower().split('_')\n        topics.extend([part for part in name_parts if len(part) > 2])\n        \n        # Simple keyword extraction from content\n        common_words = {'the', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with', 'by'}\n        words = content.lower().split()\n        word_freq = {}\n        \n        for word in words:\n            word = word.strip('.,!?\";()[]{}')\n            if len(word) > 3 and word not in common_words:\n                word_freq[word] = word_freq.get(word, 0) + 1\n        \n        # Get top 5 most frequent words as topics\n        top_words = sorted(word_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n        topics.extend([word for word, count in top_words])\n        \n        return list(set(topics))[:10]  # Limit to 10 unique topics\n    \n    @classmethod\n    def _determine_archetype(cls, filepath: Path, content: str) -> str:\n        \"\"\"Determine archetype based on file type and content.\"\"\"\n        file_ext = filepath.suffix.lower()\n        \n        # Map file types to archetypes\n        archetype_mapping = {\n            '.py': 'Alchemist',\n            '.js': 'Alchemist', \n            '.ts': 'Alchemist',\n            '.md': 'Scribe',\n            '.txt': 'Scribe',\n            '.pdf': 'Sage',\n            '.jpg': 'Visionary',\n            '.jpeg': 'Visionary',\n            '.png': 'Visionary',\n            '.mp4': 'Storyteller',\n            '.json': 'Oracle',\n            '.csv': 'Oracle',\n            '.zip': 'Guardian'\n        }\n        \n        return archetype_mapping.get(file_ext, 'Discoverer')\n    \n    @classmethod\n    def _generate_skills(cls, filepath: Path, content: str) -> List[str]:\n        \"\"\"Generate skills based on file type and content.\"\"\"\n        skills = []\n        file_ext = filepath.suffix.lower()\n        \n        # Base skill from file processing\n        skills.append(f\"nano_warden_universal_ingest_{file_ext.replace('.', '')}.py\")\n        \n        # Add content-specific skills\n        if 'class ' in content or 'def ' in content:\n            skills.append(\"nano_warden_code_analyzer.py\")\n        if 'import ' in content:\n            skills.append(\"nano_warden_dependency_tracker.py\")\n        if any(word in content.lower() for word in ['memory', 'block', 'muse']):\n            skills.append(\"nano_warden_memory_system.py\")\n        \n        return skills\n    \n    @classmethod\n    def _determine_project(cls, filepath: Path, content: str) -> str:\n        \"\"\"Determine project based on path and content.\"\"\"\n        path_parts = filepath.parts\n        \n        # Check for common project patterns\n        if 'muse' in str(filepath).lower():\n            return 'muse.pantheon'\n        elif 'blog' in str(filepath).lower():\n            return 'blog.agent'\n        elif 'warden' in str(filepath).lower():\n            return 'warden.system'\n        elif any(part in ['test', 'tests'] for part in path_parts):\n            return 'testing.framework'\n        else:\n            return 'general.development'",
  "topics": [
    "return",
    "py",
    "memory",
    "path",
    "from",
    "content",
    "content:",
    "block"
  ],
  "skills": [
    "nano_warden_universal_ingest_py.py",
    "nano_warden_code_analyzer.py",
    "nano_warden_dependency_tracker.py",
    "nano_warden_memory_system.py"
  ],
  "date": "2025-09-17",
  "project": "general.development",
  "archetype": "Alchemist",
  "created_at": "2025-09-17T18:19:13.040773+00:00",
  "source_path": "common/memory_block.py",
  "file_type": ".py",
  "pii_redacted": false,
  "consent_logged": true,
  "ethics_review": "passed",
  "links": [],
  "parent_blocks": [],
  "metadata": {
    "file_size": 8736,
    "source": "file_ingest",
    "validation_status": "passed"
  }
}