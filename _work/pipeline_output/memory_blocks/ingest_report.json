{
  "ingest_stats": {
    "processed": 9,
    "failed": 0,
    "skipped": 0,
    "total_files": 9
  },
  "memory_blocks_created": 9,
  "output_directory": "_work/pipeline_output/memory_blocks",
  "block_summaries": [
    {
      "id_hash": "0825c53afa86",
      "summary": "#!/usr/bin/env python3\n\"\"\"\nQuick Launcher for MUSE Pantheon Universal Ingest Pipeline\nProvides sensible defaults for common use cases\n\"\"\"\nimport sys\nimport argparse\nfrom pathlib import Path\nimport sub...",
      "archetype": "Alchemist",
      "project": "general.development",
      "source_path": "run_pipeline.py"
    },
    {
      "id_hash": "a35de510f005",
      "summary": "#!/usr/bin/env python3\n\"\"\"\nMUSE Pantheon MemoryBlock Schema\nCore data structure for immutable, atomic, sovereign, and semantic memory blocks.\n\"\"\"\nimport hashlib\nimport json\nfrom datetime import datetime, timezone\nfrom typing import Dict, List, Any, Optional\nfrom dataclasses import dataclass, asdict\nfrom pathlib import Path\n\n\n@dataclass\nclass MemoryBlock:\n    \"\"\"\n    Atomic, immutable, sovereign, and semantic memory block.\n    Core data structure for the MUSE Pantheon system.\n    \"\"\"\n    # Core identification\n    id_hash: str\n    summary: str\n    content: str\n    \n    # Metadata\n    topics: List[str]\n    skills: List[str]\n    date: str\n    project: str\n    archetype: str\n    \n    # System fields\n    created_at: str = \"\"\n    source_path: Optional[str] = None\n    file_type: Optional[str] = None\n    \n    # Ethics and consent tracking\n    pii_redacted: bool = False\n    consent_logged: bool = True\n    ethics_review: str = \"passed\"\n    \n    # Relationships\n    links: List[str] = None\n    parent_blocks: List[str] = None\n    \n    # Additional metadata\n    metadata: Dict[str, Any] = None\n    \n    def __post_init__(self):\n        \"\"\"Initialize default values and validate required fields.\"\"\"\n        if self.links is None:\n            self.links = []\n        if self.parent_blocks is None:\n            self.parent_blocks = []\n        if self.metadata is None:\n            self.metadata = {}\n            \n        # Generate hash if not provided\n        if not self.id_hash:\n            self.id_hash = self.generate_hash()\n            \n        # Set created_at if not provided\n        if not self.created_at:\n            self.created_at = datetime.now(timezone.utc).isoformat()\n\n    def generate_hash(self) -> str:\n        \"\"\"Generate SHA256 hash from content and metadata.\"\"\"\n        content_for_hash = f\"{self.summary}:{self.content}:{self.date}\"\n        return hashlib.sha256(content_for_hash.encode()).hexdigest()[:12]\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary for JSON serialization.\"\"\"\n        return asdict(self)\n\n    def to_json(self) -> str:\n        \"\"\"Convert to JSON string.\"\"\"\n        return json.dumps(self.to_dict(), indent=2, ensure_ascii=False)\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'MemoryBlock':\n        \"\"\"Create MemoryBlock from dictionary.\"\"\"\n        return cls(**data)\n\n    @classmethod\n    def from_json(cls, json_str: str) -> 'MemoryBlock':\n        \"\"\"Create MemoryBlock from JSON string.\"\"\"\n        return cls.from_dict(json.loads(json_str))\n\n    def save(self, output_dir: Path) -> Path:\n        \"\"\"Save memory block to file.\"\"\"\n        output_dir.mkdir(parents=True, exist_ok=True)\n        filename = f\"memory_block_{self.id_hash}.json\"\n        filepath = output_dir / filename\n        \n        with open(filepath, 'w', encoding='utf-8') as f:\n            f.write(self.to_json())\n            \n        return filepath\n\n    def validate(self) -> bool:\n        \"\"\"Validate memory block structure and content.\"\"\"\n        required_fields = ['id_hash', 'summary', 'content', 'topics', 'date', 'archetype']\n        for field in required_fields:\n            if not getattr(self, field):\n                return False\n        return True\n\n\nclass MemoryBlockFactory:\n    \"\"\"Factory for creating MemoryBlocks from various sources.\"\"\"\n    \n    ARCHETYPES = [\n        \"Discoverer\", \"Guardian\", \"Alchemist\", \"Oracle\", \"Sage\", \"Shaman\",\n        \"Visionary\", \"Architect\", \"Weaver\", \"Navigator\", \"Storyteller\", \"Scribe\"\n    ]\n    \n    @classmethod\n    def create_from_file(cls, filepath: Path, content: str, summary: str = None) -> MemoryBlock:\n        \"\"\"Create MemoryBlock from file content.\"\"\"\n        # Generate summary if not provided\n        if not summary:\n            summary = cls._generate_summary(content, filepath)\n        \n        # Extract topics from content\n        topics = cls._extract_topics(content, filepath)\n        \n        # Determine archetype based on content type\n        archetype = cls._determine_archetype(filepath, content)\n        \n        # Generate skills based on file type and content\n        skills = cls._generate_skills(filepath, content)\n        \n        # Determine project based on path and content\n        project = cls._determine_project(filepath, content)\n        \n        return MemoryBlock(\n            id_hash=\"\",  # Will be generated in __post_init__\n            summary=summary,\n            content=content,\n            topics=topics,\n            skills=skills,\n            date=datetime.now().strftime(\"%Y-%m-%d\"),\n            project=project,\n            archetype=archetype,\n            source_path=str(filepath),\n            file_type=filepath.suffix.lower(),\n            metadata={\n                \"file_size\": filepath.stat().st_size if filepath.exists() else 0,\n                \"source\": \"file_ingest\",\n                \"validation_status\": \"pending\"\n            }\n        )\n    \n    @classmethod\n    def _generate_summary(cls, content: str, filepath: Path) -> str:\n        \"\"\"Generate summary from content.\"\"\"\n        # Simple summary generation - first few sentences or truncated content\n        sentences = content.split('. ')\n        if len(sentences) > 2:\n            return '.",
      "archetype": "Alchemist",
      "project": "general.development",
      "source_path": "common/memory_block.py"
    },
    {
      "id_hash": "54ae33c5bf0a",
      "summary": "#!/usr/bin/env python3\n\"\"\"\nProject Assignment System for MUSE Pantheon\nAuto-assigns project IDs based on content analysis and archetype mapping\n\"\"\"\nimport sys\nimport argparse\nimport json\nimport loggin...",
      "archetype": "Alchemist",
      "project": "warden.system",
      "source_path": "warden/tools/assign_projects.py"
    },
    {
      "id_hash": "e599b43cff6a",
      "summary": "#!/usr/bin/env python3\n\"\"\"\nMUSE Pantheon Universal Ingest Pipeline Orchestrator\nComplete pipeline: Ingest \u2192 Cluster \u2192 Assign Projects \u2192 Report\n\"\"\"\nimport sys\nimport pathlib\nimport argparse\nimport subprocess\nimport json\nimport logging\nfrom datetime import datetime, timezone\nfrom typing import List, Dict, Any\n\n# Setup logging\nlogging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\nlogger = logging.getLogger(__name__)\n\n\nclass PipelineOrchestrator:\n    \"\"\"Orchestrates the complete MUSE Pantheon ingest pipeline\"\"\"\n\n    def __init__(self, workspace_root: str):\n        self.workspace_root = pathlib.Path(workspace_root)\n        self.tools_dir = self.workspace_root / \"warden\" / \"tools\"\n        self.output_base = self.workspace_root / \"_work\" / \"pipeline_output\"\n        self.output_base.mkdir(parents=True, exist_ok=True)\n\n    def run_ingestion(self, roots: List[str], file_types: List[str] = None) -> bool:\n        \"\"\"Run the universal ingestion phase\"\"\"\n        logger.info(\"\ud83d\ude80 PHASE 1: Universal File Ingestion\")\n        logger.info(\"-\" * 40)\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"universal_ingest.py\"),\n            \"--roots\"\n        ] + roots + [\n            \"--output\", str(self.output_base / \"memory_blocks\")\n        ]\n\n        if file_types:\n            cmd.extend([\"--types\"] + file_types)\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"\u2705 Ingestion completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"\u274c Ingestion failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"\u274c Ingestion error: {e}\")\n            return False\n\n    def run_clustering(self) -> bool:\n        \"\"\"Run the clustering and embedding phase\"\"\"\n        logger.info(\"\\n\ud83e\udde0 PHASE 2: Clustering & Embeddings\")\n        logger.info(\"-\" * 40)\n\n        blocks_dir = self.output_base / \"memory_blocks\"\n        if not blocks_dir.exists() or not any(blocks_dir.glob(\"*.json\")):\n            logger.error(\"\u274c Memory blocks directory not found or empty. Run ingestion first.\")\n            return False\n\n        cmd = [\n            sys.executable,\n            str(self.tools_dir / \"cluster_embeddings.py\"),\n            \"--blocks-dir\", str(blocks_dir),\n            \"--output-dir\", str(self.output_base / \"clustering_results\")\n        ]\n\n        try:\n            result = subprocess.run(cmd, capture_output=True, text=True, cwd=self.workspace_root)\n            if result.returncode == 0:\n                logger.info(\"\u2705 Clustering completed successfully\")\n                logger.info(result.stdout)\n                return True\n            else:\n                logger.error(f\"\u274c Clustering failed: {result.stderr}\")\n                return False\n        except Exception as e:\n            logger.error(f\"\u274c Clustering error: {e}\")\n            return False\n\n    def run_project_assignment(self) -> bool:\n        \"\"\"Run the project assignment phase\"\"\"\n        logger.info(\"\\n\ud83c\udfaf PHASE 3: Project Assignment\")\n        logger.info(\"-\" * 40)\n\n        blocks_dir = self.output_base / \"memory_blocks\"\n        clusters_file = self.output_base / \"clustering_results\" / \"clustering_results.json\"\n\n        if not blocks_dir.exists():\n            logger.error(\"\u274c Memory blocks directory not found.",
      "archetype": "Alchemist",
      "project": "warden.system",
      "source_path": "warden/tools/run_full_pipeline.py"
    },
    {
      "id_hash": "dc1904cd6796",
      "summary": "#!/usr/bin/env python3\n\"\"\"\nClustering and Embeddings System for MUSE Pantheon\nGroups MemoryBlocks semantically and generates embeddings\n\"\"\"\nimport sys\nimport argparse\nimport json\nimport logging\nfrom p...",
      "archetype": "Alchemist",
      "project": "warden.system",
      "source_path": "warden/tools/cluster_embeddings.py"
    },
    {
      "id_hash": "99264cdb873f",
      "summary": "#!/usr/bin/env python3\n\"\"\"\nUniversal File Ingest System for MUSE Pantheon\nProcesses any file format and converts to MemoryBlocks\n\"\"\"\nimport sys\nimport argparse\nimport json\nimport logging\nfrom pathlib ...",
      "archetype": "Alchemist",
      "project": "warden.system",
      "source_path": "warden/tools/universal_ingest.py"
    },
    {
      "id_hash": "ca84b863aae4",
      "summary": "# MUSE Pantheon Universal Ingest Pipeline\n\nA comprehensive system for converting any file format into structured, semantic MemoryBlocks for AI agent memory systems.\n\n## Quick Start\n\n```bash\n# Process ...",
      "archetype": "Scribe",
      "project": "general.development",
      "source_path": "README.md"
    },
    {
      "id_hash": "069098a5bbb9",
      "summary": "# MUSE Pantheon Universal Ingest Pipeline\n\n## Overview\n\nThe MUSE Pantheon Universal Ingest Pipeline is a comprehensive system for converting any file format into structured, semantic MemoryBlocks. It processes files, extracts content, generates embeddings, clusters similar content, and assigns project hierarchies - all while maintaining ethics tracking and consent logging.\n\n## Architecture\n\n### Core Components\n\n1.",
      "archetype": "Scribe",
      "project": "general.development",
      "source_path": "PIPELINE_DOCS.md"
    },
    {
      "id_hash": "7a0be1f45a1b",
      "summary": "# MUSE Pantheon Universal Ingest Pipeline\n\n## Overview\n\nAI coding agents working in this repository should understand that this is the **MUSE Pantheon Universal Ingest Pipeline** - a comprehensive system for converting any file format into structured, semantic MemoryBlocks for AI agent memory systems.\n\n## Core Architecture\n\n### Memory Block System\n- **Atomic, immutable, sovereign, semantic** memory blocks are the foundation\n- Schema defined in `common/memory_block.py` with 12 archetypes: Discoverer, Guardian, Alchemist, Oracle, Sage, Shaman, Visionary, Architect, Weaver, Navigator, Storyteller, Scribe\n- Ethics tracking built-in: `pii_redacted`, `consent_logged`, `ethics_review`\n- Each block has: `id_hash`, `summary`, `content`, `topics`, `skills`, `archetype`, `project`\n\n### Pipeline Flow\n1. **Universal Ingest** (`warden/tools/universal_ingest.py`) - Processes any file type\n2.",
      "archetype": "Scribe",
      "project": "general.development",
      "source_path": ".github/copilot-instructions.md"
    }
  ]
}